{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.stats import itemfreq\n",
    "from statistics import mode\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class decision_tree:\n",
    "    \n",
    "    class node:\n",
    "        def __init__(self, left, right, split_rule, is_leaf, label):\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.split_rule = split_rule\n",
    "            self.is_leaf = is_leaf\n",
    "            self.label = label\n",
    "    \n",
    "    def __init__(self, max_depth=1e10):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def max_count(self, lst):\n",
    "        return max(set(lst), key=list(lst).count)\n",
    "        \n",
    "    # utility function for entropy calculation\n",
    "    def entropy(self, indices):\n",
    "        p = itemfreq(a)[:, 1].astype(float) / len(indices)\n",
    "        return -p.dot(np.log2(p))\n",
    "    \n",
    "    # calculate entropy the number of instances in each class in known\n",
    "    def entropy_n(self, all_n):\n",
    "        p = all_n / (np.sum(all_n)+1e-20)\n",
    "        return -p.dot(np.log2(p+1e-20))\n",
    "    \n",
    "    # calculate the impurity(\"badness\") of the specified split on the input data\n",
    "    def impurity(self, left_label_hist, right_label_hist):\n",
    "        Sl = np.sum(left_label_hist)\n",
    "        Sr = np.sum(right_label_hist)\n",
    "        return (Sl*self.entropy_n(left_label_hist) + Sr * self.entropy_n(right_label_hist)) / (Sl+Sr)\n",
    "    \n",
    "    # find the threshold that best split the data points with a certain feature\n",
    "    # Note: <= th goes to S_left and > th goes to S_right\n",
    "    def find_threshold(self, feature, labels):\n",
    "        all_f = sorted(set(feature)) # sorted in ascending order\n",
    "        all_l = set(labels) # list unique labels\n",
    "        \n",
    "        freq_mat = np.zeros([len(all_f), len(all_l)])\n",
    "        for i, f in enumerate(all_f):\n",
    "            for j, l in enumerate(all_l):\n",
    "                freq_mat[i, j] = len(labels[np.where(labels[np.where(feature==f)]==l)])\n",
    "        \n",
    "        # calculate the average of two neighboring values as threshold\n",
    "        # iterates from min to max\n",
    "        all_threshold = (np.hstack((all_f[1:], all_f[-1])) + all_f) / 2.\n",
    "        \n",
    "        # in the beginning, all goes to the right node\n",
    "        n_left = np.zeros([len(all_l)])\n",
    "        n_right = np.sum(freq_mat, axis=0)\n",
    "        n_left_sum = 0\n",
    "        min_threshold = all_threshold[0]\n",
    "        min_H = self.impurity(n_left, n_right)\n",
    "        # loop through all threshold to find the one with the minimum impurity\n",
    "        for i, th in enumerate(all_threshold):\n",
    "            n_left += freq_mat[i, :]\n",
    "            n_right -= freq_mat[i, :]\n",
    "            H = self.impurity(n_left, n_right)\n",
    "            if H < min_H:\n",
    "                min_H = H\n",
    "                min_threshold = th\n",
    "        return min_threshold, min_H\n",
    "    \n",
    "    \n",
    "    # find the best feature and threshold to split data points\n",
    "    def segmenter(self, data, labels, m=-1):\n",
    "        d = data.shape[1]\n",
    "        if m == -1:\n",
    "            all_features = np.arange(d)\n",
    "        else:\n",
    "            all_features = np.random.choice(range(d), m, replace=False)\n",
    "        min_H = 1e20\n",
    "        min_th = 0\n",
    "        min_i = 0\n",
    "        for i in all_features:\n",
    "            threshold, H = self.find_threshold(data[:, i], labels)\n",
    "            if H < min_H:\n",
    "                min_H = H\n",
    "                min_th = threshold\n",
    "                min_i = i\n",
    "        return min_i, min_th\n",
    "    \n",
    "    # the recurrence function that builds the decision tree\n",
    "    def grow_tree(self, S, depth, m=-1):\n",
    "        if len(set(self.labels[S])) == 1 or depth >= self.max_depth: # pure node or reach maximum depth\n",
    "            return self.node(left=None, right=None, split_rule=None, is_leaf=1, label=self.max_count(self.labels[S]))\n",
    "        else:\n",
    "            min_i, min_th = self.segmenter(self.data[S, :], self.labels[S], m=m)\n",
    "            # the following comprehension might be slow\n",
    "#             Sl = [j for j, x in enumerate(self.data[:, min_i]) if x <= min_th and j in S]\n",
    "#             Sr = [j for j, x in enumerate(self.data[:, min_i]) if x > min_th and j in S]\n",
    "            # update: faster:\n",
    "            Sl = [j for j in S if self.data[j, min_i] <= min_th]\n",
    "            Sr = [j for j in S if self.data[j, min_i] > min_th]\n",
    "            # another: faster:\n",
    "#             Sl = np.intersect1d(np.where(self.data[:, min_i] <= min_th), S)\n",
    "#             Sr = np.intersect1d(np.where(self.data[:, min_i] > min_th), S)\n",
    "            if len(Sl) == 0 or len(Sr) == 0:\n",
    "                return self.node(left=None, right=None, split_rule=None, is_leaf=1, \\\n",
    "                                 label=self.max_count(self.labels[S]))\n",
    "            else:\n",
    "                return self.node(left=self.grow_tree(Sl,depth+1), right=self.grow_tree(Sr,depth+1), split_rule = (min_i, min_th), \\\n",
    "                            is_leaf=0, label=None)\n",
    "        \n",
    "    # train the decision tree\n",
    "    def train(self, data, labels, m=-1):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        S = np.array(range(len(labels)))\n",
    "        self.root = self.grow_tree(S, 1, m=m)\n",
    "        \n",
    "    # predict labels of test data\n",
    "    def predict(self, data, verbose=False):\n",
    "        if data.ndim == 1: # special case of only 1 row (it becomes a 1d vector in numpy)\n",
    "            data = np.reshape(data, [1, len(data)])\n",
    "            N = 1\n",
    "        else:\n",
    "            N = data.shape[0]\n",
    "        labels = np.zeros(N)    \n",
    "            \n",
    "        # predict each data point    \n",
    "        for i in range(N):\n",
    "            d = data[i, :]\n",
    "            current_node = self.root\n",
    "            # going down along the tree\n",
    "            while not current_node.is_leaf: # not reach leaf yet\n",
    "                idx = current_node.split_rule[0]\n",
    "                th = current_node.split_rule[1]\n",
    "                if d[idx] <= th:\n",
    "                    current_node = current_node.left\n",
    "                    if verbose:\n",
    "                        print('Going left')\n",
    "                else:\n",
    "                    current_node = current_node.right\n",
    "                    if verbose:\n",
    "                        print('Going right')\n",
    "            if verbose:\n",
    "                print()\n",
    "                \n",
    "            labels[i] = current_node.label\n",
    "        return labels\n",
    "\n",
    "    # calculate the prediction accuracy\n",
    "    def accuracy(self, data, true_labels):\n",
    "        labels = self.predict(data, verbose=False)\n",
    "        N = len(labels)\n",
    "        return np.sum(labels == true_labels) / float(N)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class random_forest:\n",
    "    def __init__(self, n_trees=20, n_sample=1000, n_feature=-1, max_depth=1e10):\n",
    "        self.n_trees = n_trees\n",
    "        self.n_sample = n_sample\n",
    "        self.n_feature = -1\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = np.array([decision_tree(max_depth)] * n_trees)\n",
    "        \n",
    "    def train(self, data, labels):\n",
    "        if self.n_feature == -1:\n",
    "            d = data.shape[1]\n",
    "            self.n_feature = int(np.sqrt(d)) # num of random features = sqrt(d) is a good guess\n",
    "        for dt in self.trees:\n",
    "            idx = np.random.choice(range(len(data)), self.n_sample)\n",
    "            dt.train(data[idx, :], labels[idx], m=self.n_feature) # activate the random feature mode\n",
    "    \n",
    "    def predict(self, data, verbose=False):\n",
    "        if data.ndim == 1: # special case of only 1 row (it becomes a 1d vector in numpy)\n",
    "            data = np.reshape(data, [1, len(data)])\n",
    "            N = 1\n",
    "        else:\n",
    "            N = data.shape[0]\n",
    "        labels = np.zeros(N)    \n",
    "            \n",
    "        # predict each data point    \n",
    "        for i in range(N):\n",
    "            votes = np.zeros(self.n_trees)\n",
    "            for j, t in enumerate(self.trees):\n",
    "                votes[j] = t.predict(data[i, :], verbose=verbose)\n",
    "            labels[i] = t.max_count(votes)\n",
    "        return labels\n",
    "    \n",
    "    def accuracy(self, data, true_labels):\n",
    "        labels = self.predict(data, verbose=False)\n",
    "        N = len(labels)\n",
    "        return np.sum(labels == true_labels) / float(N)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23702"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat('./spam_dist/spam_data.mat')\n",
    "train_X = data['training_data']\n",
    "train_y = data['training_labels'].ravel()\n",
    "test_X = data['test_data']\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18961, 32)\n"
     ]
    }
   ],
   "source": [
    "S = np.random.choice(range(len(train_y)), int(len(train_y)/5*4), replace=False)\n",
    "train_data = train_X[S, :]\n",
    "train_labels = train_y[S]\n",
    "S = np.setdiff1d(range(len(train_y)), S)\n",
    "validation_data = train_X[S, :]\n",
    "validation_labels = train_y[S]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time:  5.8212339878082275\n",
      "Accuracy:  0.793503480278\n"
     ]
    }
   ],
   "source": [
    "dt = decision_tree(15)\n",
    "start = time.time()\n",
    "dt.train(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Total training time: ', end-start)\n",
    "\n",
    "l = dt.accuracy(validation_data, validation_labels)\n",
    "print('Accuracy: ', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time:  14.86953616142273\n",
      "Accuracy:  0.740139211137\n"
     ]
    }
   ],
   "source": [
    "n_trees=80\n",
    "n_sample=1000\n",
    "n_feature=15\n",
    "max_depth=10\n",
    "rf = random_forest(n_trees=n_trees, n_sample=n_sample, n_feature=n_feature, max_depth=n_feature)\n",
    "start = time.time()\n",
    "rf.train(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Total training time: ', end-start)\n",
    "\n",
    "l = rf.accuracy(validation_data, validation_labels)\n",
    "print('Accuracy: ', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import glob\n",
    "SPAM_DIR = 'spam/'\n",
    "HAM_DIR = 'ham/'\n",
    "TEST_DIR = 'test/'\n",
    "NUM_TEST_EXAMPLES = 10000\n",
    "spam_filenames = glob.glob('spam_dist/' + SPAM_DIR + '*.txt')\n",
    "ham_filenames = glob.glob('spam_dist/' + HAM_DIR + '*.txt')\n",
    "test_filenames = ['spam_dist/' + TEST_DIR + str(x) + '.txt' for x in range(NUM_TEST_EXAMPLES)]\n",
    "\n",
    "all_text = []\n",
    "for file in spam_filenames+ham_filenames: # use only training set data to build BOG\n",
    "    with open(file, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        all_text.append(f.read())\n",
    "        \n",
    "all_test_text = []\n",
    "for file in test_filenames: # use only training set data to build BOG\n",
    "    with open(file, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        all_test_text.append(f.read())\n",
    "        \n",
    "vectorizer = CountVectorizer(min_df=4) # min word length=4\n",
    "train_X = vectorizer.fit_transform(all_text).toarray()\n",
    "test_X = vectorizer.transform(all_test_text).toarray()\n",
    "train_y = np.concatenate((np.ones(len(spam_filenames)), np.zeros(len(ham_filenames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23702, 41921)\n",
      "(10000, 41921)\n",
      "(23702,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_y = rf.predict(test_X)\n",
    "df = pd.DataFrame({'Category': test_y.astype(int)})\n",
    "df.index.rename('Id', inplace=True)\n",
    "df.to_csv('spam_dist/spam_rf_%d_%d_%d_%d.csv' % (n_trees, n_sample, n_feature, max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32724, 15)\n",
      "(16118, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>307423</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>192965</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>Private</td>\n",
       "      <td>125591</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>124963</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>146103</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   59       Private  307423           9th              5       Never-married   \n",
       "1   32       Private  192965       HS-grad              9           Separated   \n",
       "2   19       Private  125591  Some-college             10       Never-married   \n",
       "3   51   Without-pay  124963    Assoc-acdm             12  Married-civ-spouse   \n",
       "4   57  Self-emp-inc  146103       HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "      occupation   relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Other-service  Not-in-family  Black    Male             0             0   \n",
       "1          Sales  Not-in-family  White  Female             0             0   \n",
       "2  Other-service      Own-child  White  Female             0             0   \n",
       "3          Sales        Husband  White    Male             0             0   \n",
       "4          Sales        Husband  White    Male         15024             0   \n",
       "\n",
       "   hours-per-week native-country  label  \n",
       "0              50  United-States      0  \n",
       "1              45  United-States      0  \n",
       "2              40  United-States      0  \n",
       "3              45  United-States      0  \n",
       "4              30  United-States      1  "
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./census_dist/train_data.csv')\n",
    "test_data = pd.read_csv('./census_dist/test_data.csv')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/OQ 392086</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17760</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC/PARIS 2133</td>\n",
       "      <td>15.0458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211535</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   sex   age  sibsp  parch           ticket      fare  \\\n",
       "0       0.0     3.0  male   NaN    0.0    0.0  SOTON/OQ 392086    8.0500   \n",
       "1       0.0     1.0  male  22.0    0.0    0.0         PC 17760  135.6333   \n",
       "2       0.0     2.0  male  23.0    0.0    0.0    SC/PARIS 2133   15.0458   \n",
       "3       0.0     2.0  male  42.0    0.0    0.0           211535   13.0000   \n",
       "4       0.0     3.0  male  20.0    0.0    0.0             7534    9.8458   \n",
       "\n",
       "  cabin embarked  \n",
       "0   NaN        S  \n",
       "1   NaN        C  \n",
       "2   NaN        C  \n",
       "3   NaN        S  \n",
       "4   NaN        S  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./titanic_dist/titanic_training.csv')\n",
    "test_data = pd.read_csv('./titanic_dist/titanic_testing_data.csv')\n",
    "train_data.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
